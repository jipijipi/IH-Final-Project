{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food in Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('config.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = load_all_datasets(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load correspondance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondance_data = all_data['ids']\n",
    "correspondance_data.drop_duplicates(inplace=True)\n",
    "correspondance_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load paintings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_data = all_data['paintings']\n",
    "paintings_data['image_url'] = paintings_data['image_url'].apply(lambda x: get_512px_thumbnail(x) if pd.notna(x) else x)\n",
    "paintings_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load locations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_data = all_data['locations']\n",
    "locations_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load authors data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_data = all_data['authors']\n",
    "authors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ML food data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_words = all_data['food_words']\n",
    "food_words['food_word_detected'] = food_words.select_dtypes(include='int').sum(axis=1) > 0\n",
    "food_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_found = all_data['food_found']\n",
    "food_found['food_image_detected'] = food_found['predictions'].apply(lambda x: len(x) > 3)\n",
    "food_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_detected_df = food_words.merge(food_found, on='painting_id', how='outer')\n",
    "food_detected_df['food_detected'] = (food_detected_df['food_word_detected'] | food_detected_df['food_image_detected']).astype(int)\n",
    "food_detected_df = food_detected_df[['painting_id', 'food_detected']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "password = os.getenv('PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the Database\n",
    "database_name = 'art_and_food_db'\n",
    "\n",
    "# Set Up Database Connection\n",
    "engine = create_engine(f'mysql+pymysql://root:{password}@localhost')\n",
    "\n",
    "# Create Database if it Doesn't Exist\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f'CREATE DATABASE IF NOT EXISTS {database_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Newly Created Database\n",
    "engine = create_engine(\n",
    "    f'mysql+pymysql://root:{password}@localhost/{database_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Date, DateTime, Float, ForeignKey, Text, Boolean\n",
    "#from geoalchemy2 import Geometry\n",
    "#from datetime import datetime\n",
    "\n",
    "# Create MetaData instance\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define tables\n",
    "paintings = Table('paintings', metadata,\n",
    "    Column('painting_id', String(50), primary_key=True),\n",
    "    Column('creation_date', Integer),\n",
    "    Column('title', String(255)),\n",
    "    Column('image_url', Text),\n",
    "    Column('time_period', String(100))\n",
    ")\n",
    "\n",
    "locations = Table('locations', metadata,\n",
    "    Column('location_id', String(50), primary_key=True),\n",
    "    Column('location_name', String(255)),\n",
    "    Column('location_country', String(100)),\n",
    "    Column('coordinates', String(100))\n",
    ")\n",
    "\n",
    "authors = Table('authors', metadata,\n",
    "    Column('author_id', String(50), primary_key=True),\n",
    "    Column('painter', String(255)),\n",
    "    Column('author_country', String(100)),\n",
    "    Column('date_of_birth', Integer),\n",
    "    Column('author_gender', String(50))\n",
    ")\n",
    "\n",
    "food_detected = Table('food_detected', metadata,\n",
    "    Column('painting_id', String(50), primary_key=True),\n",
    "    Column('food_detected', Boolean),\n",
    ")\n",
    "\n",
    "\n",
    "correspondence = Table('correspondence', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('painting_id', String(50)),\n",
    "    Column('author_id', String(50)),\n",
    "    Column('location_id', String(50))\n",
    ")\n",
    "\n",
    "\"\"\" food_detected = Table('food_detected', metadata,\n",
    "    Column('painting_id', String(50), ForeignKey('paintings.painting_id'), primary_key=True),\n",
    "    Column('food_detected', Boolean),\n",
    ")\n",
    "\n",
    "correspondence = Table('correspondence', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('painting_id', String(50), ForeignKey('paintings.painting_id'), nullable=False),\n",
    "    Column('author_id', String(50), ForeignKey('authors.author_id')),\n",
    "    Column('location_id', String(50), ForeignKey('locations.location_id'))\n",
    ") \"\"\"\n",
    "\n",
    "def create_tables(engine):\n",
    "    metadata.create_all(engine)\n",
    "    \n",
    "\n",
    "def insert_data(engine, paintings_df, locations_df, authors_df, food_detected_df, correspondence_df):\n",
    "    connection = engine.connect()\n",
    "    \n",
    "    try:\n",
    "        # Insert Locations\n",
    "        #locations_df = locations_df.dropna(how='any')\n",
    "        location_data = locations_df.to_dict(orient='records')\n",
    "        if location_data:\n",
    "            connection.execute(locations.insert(), location_data)\n",
    "        \n",
    "        # Insert Authors\n",
    "        #authors_df = authors_df.dropna(how='any')\n",
    "        author_data = authors_df.to_dict(orient='records')\n",
    "        if author_data:\n",
    "            connection.execute(authors.insert(), author_data)\n",
    "        \n",
    "        # Insert Paintings\n",
    "        #paintings_df = paintings_df.dropna(how='any')\n",
    "        painting_data = paintings_df.to_dict(orient='records')\n",
    "        if painting_data:\n",
    "            connection.execute(paintings.insert(), painting_data)\n",
    "        \n",
    "        #paintings_df = paintings_df.dropna(how='any')\n",
    "        food_detected_data = food_detected_df.to_dict(orient='records')\n",
    "        if painting_data:\n",
    "            connection.execute(food_detected.insert(), food_detected_data)\n",
    "            \n",
    "        # Insert Correspondence\n",
    "        #correspondence_df = correspondence_df.dropna(how='any')\n",
    "        correspondence_data = correspondence_df.to_dict(orient='records')\n",
    "        if correspondence_data:\n",
    "            connection.execute(correspondence.insert(), correspondence_data)\n",
    "        \n",
    "        connection.commit()\n",
    "    \n",
    "    except Exception as e:\n",
    "        connection.rollback()\n",
    "        raise e\n",
    "    \n",
    "    finally:\n",
    "        connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_tables(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataframes to the SQL database\n",
    "paintings_data.to_sql('paintings', engine, if_exists='append', index=False)\n",
    "authors_data.to_sql('authors', engine, if_exists='append', index=False)\n",
    "locations_data.to_sql('locations', engine, if_exists='append', index=False)\n",
    "food_detected_df.to_sql('food_detected', engine, if_exists='append', index=False)\n",
    "correspondance_data.to_sql('correspondence', engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Insert data\n",
    "insert_data(engine, paintings_data, locations_data, authors_data, food_detected_df, correspondance_data)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Upload dataframes to the SQL database\n",
    "correspondance_data.to_sql('correspondance_data', engine, if_exists='replace', index=False)\n",
    "paintings_data.to_sql('paintings_data', engine, if_exists='replace', index=False)\n",
    "authors_data.to_sql('authors_data', engine, if_exists='replace', index=False)\n",
    "locations_data.to_sql('locations_data', engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = correspondance_data.merge(paintings_data, on='painting_id', how='inner')\n",
    "merged_df = merged_df.merge(authors_data, on='author_id', how='left')\n",
    "merged_df = merged_df.merge(locations_data, on='location_id', how='left')\n",
    "merged_df = merged_df.merge(food_words, on='painting_id', how='left')\n",
    "merged_df = merged_df.merge(food_found, on='painting_id', how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop_duplicates(subset='painting_id', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['food_detected'] = (merged_df['food_word_detected'] | merged_df['food_image_detected']).astype(int)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[merged_df['image_path'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df['food_detected'].value_counts())\n",
    "print(merged_df['food_word_detected'].value_counts())\n",
    "print(merged_df['food_image_detected'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(merged_df[['creation_date','date_of_birth']])\n",
    "display(merged_df[['creation_date','date_of_birth']].describe())\n",
    "\n",
    "\n",
    "merged_df['creation_date'] = merged_df['creation_date'].apply(extract_year)\n",
    "merged_df['date_of_birth'] = merged_df['date_of_birth'].apply(extract_year)\n",
    "\n",
    "\n",
    "display(merged_df[['creation_date','date_of_birth']])\n",
    "display(merged_df[['creation_date','date_of_birth']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing creation year when possible\n",
    "# Calculate the age of the painter at the time of painting\n",
    "merged_df['painter_age_at_painting'] = merged_df['creation_date'] - merged_df['date_of_birth']\n",
    "\n",
    "display(merged_df[['painter', 'creation_date', 'date_of_birth', 'painter_age_at_painting']])\n",
    "\n",
    "# Calculate the average painter_age_at_painting for each painter\n",
    "avg_painter_age = merged_df['painter_age_at_painting'].mean().astype(int)\n",
    "\n",
    "merged_df['painter_age_at_painting'].fillna(avg_painter_age, inplace=True)\n",
    "\n",
    "# Fill missing creation_date with date_of_birth + avg_painter_age\n",
    "merged_df['creation_date'].fillna(merged_df['date_of_birth'] + avg_painter_age, inplace=True)\n",
    "\n",
    "display(merged_df[['painter', 'creation_date', 'date_of_birth', 'painter_age_at_painting']])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['painter'].fillna('Unknown Artist', inplace=True)\n",
    "merged_df['author_country'].fillna('Unknown Country', inplace=True)\n",
    "merged_df['location_country'].fillna('Unknown Country', inplace=True)\n",
    "merged_df['location_name'].fillna('Unknown Location', inplace=True)\n",
    "\n",
    "merged_df['author_gender'] = merged_df['author_gender'].astype('category')\n",
    "merged_df['author_gender'] = merged_df['author_gender'].cat.set_categories(['male', 'female'])\n",
    "merged_df['author_gender'].fillna('male', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a column with decades\n",
    "merged_df['decade'] = (merged_df['creation_date'] // 10) * 10\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(merged_df[['painter', 'creation_date', 'decade']])\n",
    "print(merged_df['decade'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['location_country'] = merged_df['location_country'].replace('German Reich', 'Germany')\n",
    "merged_df['author_country'] = merged_df['author_country'].replace('German Reich', 'Germany')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df['time_period'] = merged_df['decade'].apply(classify_period)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add gdp and pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_df = pd.read_csv('data/gdp_pop_decades.csv')\n",
    "eco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(\n",
    "    eco_df,\n",
    "    on='decade',\n",
    "    how='left' \n",
    ")\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize 'gdppc' and 'pop' columns\n",
    "merged_df[['gdppc_normalized', 'pop_normalized']] = scaler.fit_transform(merged_df[['gdppc', 'pop']])\n",
    "\n",
    "display(merged_df[['gdppc', 'gdppc_normalized', 'pop', 'pop_normalized']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_with_food = merged_df[merged_df['image_url'].isna() == False]\n",
    "paintings_with_food = paintings_with_food[['title', 'painter', 'creation_date', 'author_gender', 'author_country', 'location_name', 'location_country', 'time_period', 'image_path', 'image_url', 'coordinates','food_detected','decade','gdppc','pop', 'gdppc_normalized', 'pop_normalized']]\n",
    "paintings_with_food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_with_food.to_csv('data/paintings_with_food.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by decade and calculate the proportion of food_detected\n",
    "food_by_decade = merged_df.groupby('decade')['food_detected'].agg(artwork_count='count', food_related_sum='sum').reset_index()\n",
    "food_by_decade['proportion_food_detected'] = food_by_decade['food_related_sum'] / food_by_decade['artwork_count']\n",
    "\n",
    "# Merge normalized GDP and population data\n",
    "food_by_decade = food_by_decade.merge(\n",
    "    merged_df[['decade', 'gdppc_normalized', 'pop_normalized']].drop_duplicates(),\n",
    "    on='decade',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Filter the DataFrame to include only records from 1250 to 2000\n",
    "food_by_decade = food_by_decade[(food_by_decade['decade'] >= 1250) & (food_by_decade['decade'] <= 2000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = food_by_decade\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "correlation = data['proportion_food_detected'].corr(data['gdppc_normalized'])\n",
    "correlation_pvalue = stats.pearsonr(data['proportion_food_detected'], data['gdppc_normalized'])\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = {\n",
    "    'Pearson Correlation': correlation,\n",
    "    'P-value': correlation_pvalue[1],\n",
    "    'Sample Size': len(data),\n",
    "    'Mean Food Proportion': data['proportion_food_detected'].mean(),\n",
    "    'Mean GDP per Capita': data['gdppc_normalized'].mean(),\n",
    "}\n",
    "\n",
    "print(\"\\nCorrelation Analysis Results:\")\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
