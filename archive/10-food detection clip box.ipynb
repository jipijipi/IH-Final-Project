{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class CheckpointManager:\n",
    "    def __init__(self, checkpoint_dir=\"checkpoints\"):\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
    "        self.checkpoint_file = self.checkpoint_dir / \"visualization_progress.json\"\n",
    "        self.temp_results_file = self.checkpoint_dir / \"partial_visualization_results.csv\"\n",
    "        \n",
    "    def save_checkpoint(self, processed_files, current_idx, total_files):\n",
    "        checkpoint_data = {\n",
    "            'processed_files': processed_files,\n",
    "            'current_idx': current_idx,\n",
    "            'total_files': total_files,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(self.checkpoint_file, 'w') as f:\n",
    "            json.dump(checkpoint_data, f)\n",
    "            \n",
    "    def load_checkpoint(self):\n",
    "        if self.checkpoint_file.exists():\n",
    "            with open(self.checkpoint_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return None\n",
    "    \n",
    "    def save_partial_results(self, results_df):\n",
    "        results_df.to_csv(self.temp_results_file, index=False)\n",
    "    \n",
    "    def load_partial_results(self):\n",
    "        if self.temp_results_file.exists():\n",
    "            return pd.read_csv(self.temp_results_file)\n",
    "        return None\n",
    "    \n",
    "    def clear_checkpoints(self):\n",
    "        if self.checkpoint_file.exists():\n",
    "            self.checkpoint_file.unlink()\n",
    "        if self.temp_results_file.exists():\n",
    "            self.temp_results_file.unlink()\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"[Previous GradCAM implementation remains the same]\"\"\"\n",
    "    pass\n",
    "\n",
    "def visualize_prediction(image_path, model, processor, device, output_path=None, confidence_threshold=0.5):\n",
    "    \"\"\"[Previous visualize_prediction implementation remains the same]\"\"\"\n",
    "    pass\n",
    "\n",
    "def batch_process_with_visualization_and_checkpoints(\n",
    "    model, processor, image_paths, output_dir, device, \n",
    "    checkpoint_manager, batch_size=16, start_idx=0):\n",
    "    \"\"\"Process multiple images with visualization and checkpointing\"\"\"\n",
    "    \n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Load existing results if any\n",
    "    partial_results = checkpoint_manager.load_partial_results()\n",
    "    if partial_results is not None:\n",
    "        results = partial_results.to_dict('records')\n",
    "        processed_files = set(partial_results['image_path'])\n",
    "    else:\n",
    "        results = []\n",
    "        processed_files = set()\n",
    "    \n",
    "    total_images = len(image_paths)\n",
    "    \n",
    "    try:\n",
    "        # Process images in batches\n",
    "        for idx in tqdm(range(start_idx, total_images), \n",
    "                       initial=start_idx, \n",
    "                       total=total_images,\n",
    "                       desc=\"Processing images\"):\n",
    "            \n",
    "            image_path = image_paths[idx]\n",
    "            \n",
    "            # Skip if already processed\n",
    "            if str(image_path) in processed_files:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                output_path = output_dir / f\"viz_{Path(image_path).name}\"\n",
    "                \n",
    "                # Process image and generate visualization\n",
    "                image, probability = visualize_prediction(\n",
    "                    image_path,\n",
    "                    model,\n",
    "                    processor,\n",
    "                    device,\n",
    "                    output_path\n",
    "                )\n",
    "                \n",
    "                result = {\n",
    "                    'image_path': str(image_path),\n",
    "                    'output_path': str(output_path),\n",
    "                    'confidence': probability,\n",
    "                    'contains_food': probability > 0.5,\n",
    "                    'error': None,\n",
    "                    'processing_time': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                result = {\n",
    "                    'image_path': str(image_path),\n",
    "                    'output_path': None,\n",
    "                    'confidence': None,\n",
    "                    'contains_food': None,\n",
    "                    'error': str(e),\n",
    "                    'processing_time': datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            results.append(result)\n",
    "            processed_files.add(str(image_path))\n",
    "            \n",
    "            # Save checkpoint every batch_size images\n",
    "            if (idx + 1) % batch_size == 0:\n",
    "                results_df = pd.DataFrame(results)\n",
    "                checkpoint_manager.save_partial_results(results_df)\n",
    "                checkpoint_manager.save_checkpoint(\n",
    "                    list(processed_files),\n",
    "                    idx + 1,\n",
    "                    total_images\n",
    "                )\n",
    "                \n",
    "                # Print progress summary\n",
    "                success_count = results_df['error'].isna().sum()\n",
    "                print(f\"\\nProgress Summary:\")\n",
    "                print(f\"Processed: {len(results_df)} / {total_images}\")\n",
    "                print(f\"Successful: {success_count}\")\n",
    "                print(f\"Failed: {len(results_df) - success_count}\")\n",
    "                if success_count > 0:\n",
    "                    print(f\"Food detected: {results_df['contains_food'].sum()}\")\n",
    "                    print(f\"Average confidence: {results_df['confidence'].mean():.3f}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcessing interrupted. Progress has been saved.\")\n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def main():\n",
    "    # Configure parameters\n",
    "    MODEL_PATH = 'best_food_detector.pth'\n",
    "    IMAGE_DIR = 'path/to/your/images'\n",
    "    OUTPUT_DIR = 'visualizations'\n",
    "    CHECKPOINT_DIR = 'checkpoints'\n",
    "    BATCH_SIZE = 16\n",
    "    \n",
    "    # Initialize checkpoint manager\n",
    "    checkpoint_manager = CheckpointManager(CHECKPOINT_DIR)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    model, processor = load_trained_model(MODEL_PATH, device)\n",
    "    \n",
    "    # Get image paths\n",
    "    print(\"Scanning for images...\")\n",
    "    image_paths = list(Path(IMAGE_DIR).rglob('*.jpg'))\n",
    "    image_paths.extend(Path(IMAGE_DIR).rglob('*.png'))\n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "    \n",
    "    # Check for existing checkpoint\n",
    "    checkpoint = checkpoint_manager.load_checkpoint()\n",
    "    start_idx = 0\n",
    "    \n",
    "    if checkpoint:\n",
    "        print(\"\\nFound existing checkpoint:\")\n",
    "        print(f\"Images processed: {checkpoint['current_idx']} of {checkpoint['total_files']}\")\n",
    "        print(f\"Last update: {checkpoint['timestamp']}\")\n",
    "        \n",
    "        response = input(\"Would you like to resume from checkpoint? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            start_idx = checkpoint['current_idx']\n",
    "        else:\n",
    "            checkpoint_manager.clear_checkpoints()\n",
    "            print(\"Starting fresh...\")\n",
    "    \n",
    "    # Process images\n",
    "    print(\"\\nStarting visualization process...\")\n",
    "    results_df = batch_process_with_visualization_and_checkpoints(\n",
    "        model,\n",
    "        processor,\n",
    "        image_paths,\n",
    "        OUTPUT_DIR,\n",
    "        device,\n",
    "        checkpoint_manager,\n",
    "        BATCH_SIZE,\n",
    "        start_idx\n",
    "    )\n",
    "    \n",
    "    # Add additional metadata\n",
    "    results_df['filename'] = results_df['image_path'].apply(lambda x: Path(x).name)\n",
    "    results_df['directory'] = results_df['image_path'].apply(lambda x: str(Path(x).parent))\n",
    "    results_df['file_size'] = results_df['image_path'].apply(\n",
    "        lambda x: os.path.getsize(x) if os.path.exists(x) else None\n",
    "    )\n",
    "    \n",
    "    # Save final results\n",
    "    final_output = 'visualization_results.csv'\n",
    "    results_df.to_csv(final_output, index=False)\n",
    "    print(f\"\\nResults saved to {final_output}\")\n",
    "    \n",
    "    # Clear checkpoints after successful completion\n",
    "    checkpoint_manager.clear_checkpoints()\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\nFinal Summary:\")\n",
    "    print(f\"Total images processed: {len(results_df)}\")\n",
    "    print(f\"Successfully processed: {results_df['error'].isna().sum()}\")\n",
    "    print(f\"Failed to process: {results_df['error'].notna().sum()}\")\n",
    "    \n",
    "    success_mask = results_df['error'].isna()\n",
    "    if success_mask.any():\n",
    "        successful_df = results_df[success_mask]\n",
    "        print(f\"\\nFood detection results:\")\n",
    "        print(f\"Contains food: {successful_df['contains_food'].sum()}\")\n",
    "        print(f\"No food: {(~successful_df['contains_food']).sum()}\")\n",
    "        print(f\"Average confidence: {successful_df['confidence'].mean():.3f}\")\n",
    "        \n",
    "        # Save high-confidence examples to separate file\n",
    "        high_conf = successful_df[successful_df['confidence'] > 0.8]\n",
    "        if not high_conf.empty:\n",
    "            high_conf.to_csv('high_confidence_results.csv', index=False)\n",
    "            print(f\"\\nSaved {len(high_conf)} high-confidence results to high_confidence_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
