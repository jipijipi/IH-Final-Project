{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_trained_model(model_path, device):\n",
    "    \"\"\"Load the trained CLIP model\"\"\"\n",
    "    # Load base CLIP model\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    \n",
    "    # Load trained weights\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "def process_image(image_path, processor):\n",
    "    \"\"\"Process a single image for prediction\"\"\"\n",
    "    try:\n",
    "        # Open and preprocess image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = TF.resize(image, (224, 224), interpolation=TF.InterpolationMode.BICUBIC)\n",
    "        image = TF.center_crop(image, (224, 224))\n",
    "        \n",
    "        # Process using CLIP processor\n",
    "        inputs = processor(\n",
    "            images=image,\n",
    "            text=['a painting containing food', 'a painting not containing food'],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=77,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        return inputs, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "def predict_batch(model, processor, image_paths, device, batch_size=32):\n",
    "    \"\"\"Make predictions for a batch of images\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Process images in batches\n",
    "    for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Processing images\"):\n",
    "        batch_paths = image_paths[i:i + batch_size]\n",
    "        batch_inputs = []\n",
    "        batch_errors = []\n",
    "        batch_valid_indices = []\n",
    "        \n",
    "        # Process each image in the batch\n",
    "        for idx, path in enumerate(batch_paths):\n",
    "            inputs, error = process_image(path, processor)\n",
    "            if inputs is not None:\n",
    "                batch_inputs.append(inputs)\n",
    "                batch_valid_indices.append(idx)\n",
    "            batch_errors.append(error)\n",
    "        \n",
    "        if not batch_inputs:\n",
    "            # If no valid images in batch, add error results\n",
    "            for path, error in zip(batch_paths, batch_errors):\n",
    "                results.append({\n",
    "                    'image_path': str(path),\n",
    "                    'contains_food': None,\n",
    "                    'food_confidence': None,\n",
    "                    'no_food_confidence': None,\n",
    "                    'processing_time': None,\n",
    "                    'error': error if error else \"Unknown error during processing\"\n",
    "                })\n",
    "            continue\n",
    "        \n",
    "        # Combine batch inputs\n",
    "        combined_inputs = {\n",
    "            'pixel_values': torch.cat([x['pixel_values'] for x in batch_inputs]),\n",
    "            'input_ids': torch.cat([x['input_ids'] for x in batch_inputs]),\n",
    "            'attention_mask': torch.cat([x['attention_mask'] for x in batch_inputs])\n",
    "        }\n",
    "        \n",
    "        # Move to device\n",
    "        combined_inputs = {k: v.to(device) for k, v in combined_inputs.items()}\n",
    "        \n",
    "        # Make predictions\n",
    "        try:\n",
    "            start_time = datetime.now()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(\n",
    "                    input_ids=combined_inputs['input_ids'],\n",
    "                    attention_mask=combined_inputs['attention_mask'],\n",
    "                    pixel_values=combined_inputs['pixel_values']\n",
    "                )\n",
    "                \n",
    "                image_features = outputs.image_embeds\n",
    "                text_features = outputs.text_embeds\n",
    "                \n",
    "                # Calculate similarity scores\n",
    "                similarities = torch.matmul(image_features, text_features.t())\n",
    "                probs = torch.softmax(similarities, dim=-1)\n",
    "                \n",
    "            processing_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            # Process results\n",
    "            probs_np = probs.cpu().numpy()\n",
    "            \n",
    "            for idx, (path, error) in enumerate(zip(batch_paths, batch_errors)):\n",
    "                if idx in batch_valid_indices:\n",
    "                    valid_idx = batch_valid_indices.index(idx)\n",
    "                    results.append({\n",
    "                        'image_path': str(path),\n",
    "                        'contains_food': bool(probs_np[valid_idx, 0] > 0.5),\n",
    "                        'food_confidence': float(probs_np[valid_idx, 0]),\n",
    "                        'no_food_confidence': float(probs_np[valid_idx, 1]),\n",
    "                        'processing_time': processing_time / len(batch_valid_indices),\n",
    "                        'error': None\n",
    "                    })\n",
    "                else:\n",
    "                    results.append({\n",
    "                        'image_path': str(path),\n",
    "                        'contains_food': None,\n",
    "                        'food_confidence': None,\n",
    "                        'no_food_confidence': None,\n",
    "                        'processing_time': None,\n",
    "                        'error': error if error else \"Failed during processing\"\n",
    "                    })\n",
    "                    \n",
    "        except Exception as e:\n",
    "            # Handle batch processing errors\n",
    "            for path in batch_paths:\n",
    "                results.append({\n",
    "                    'image_path': str(path),\n",
    "                    'contains_food': None,\n",
    "                    'food_confidence': None,\n",
    "                    'no_food_confidence': None,\n",
    "                    'processing_time': None,\n",
    "                    'error': f\"Batch processing error: {str(e)}\"\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def scan_directory(directory_path):\n",
    "    \"\"\"Scan directory for image files\"\"\"\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}\n",
    "    image_paths = []\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(Path(directory_path).rglob(f'*{ext}'))\n",
    "        image_paths.extend(Path(directory_path).rglob(f'*{ext.upper()}'))\n",
    "    \n",
    "    return sorted(image_paths)\n",
    "\n",
    "def main():\n",
    "    # Configure these parameters\n",
    "    MODEL_PATH = 'best_food_detector.pth'  # Path to your trained model\n",
    "    IMAGE_DIR = 'img/img_512/'      # Directory containing images to process\n",
    "    OUTPUT_FILE = 'food_predictions_clip.csv'    # Output CSV file name\n",
    "    BATCH_SIZE = 32                        # Batch size for processing\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    model, processor = load_trained_model(MODEL_PATH, device)\n",
    "    \n",
    "    # Scan directory for images\n",
    "    print(\"Scanning directory for images...\")\n",
    "    image_paths = scan_directory(IMAGE_DIR)\n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"Making predictions...\")\n",
    "    results_df = predict_batch(model, processor, image_paths, device, BATCH_SIZE)\n",
    "    \n",
    "    # Add additional metadata\n",
    "    results_df['filename'] = results_df['image_path'].apply(lambda x: Path(x).name)\n",
    "    results_df['directory'] = results_df['image_path'].apply(lambda x: str(Path(x).parent))\n",
    "    results_df['file_size'] = results_df['image_path'].apply(lambda x: os.path.getsize(x) if os.path.exists(x) else None)\n",
    "    results_df['prediction_timestamp'] = datetime.now()\n",
    "    \n",
    "    # Reorder columns\n",
    "    column_order = [\n",
    "        'filename',\n",
    "        'directory',\n",
    "        'image_path',\n",
    "        'contains_food',\n",
    "        'food_confidence',\n",
    "        'no_food_confidence',\n",
    "        'file_size',\n",
    "        'processing_time',\n",
    "        'prediction_timestamp',\n",
    "        'error'\n",
    "    ]\n",
    "    results_df = results_df[column_order]\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"\\nResults saved to {OUTPUT_FILE}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nPrediction Summary:\")\n",
    "    print(f\"Total images processed: {len(results_df)}\")\n",
    "    print(f\"Successfully processed: {results_df['error'].isna().sum()}\")\n",
    "    print(f\"Failed to process: {results_df['error'].notna().sum()}\")\n",
    "    \n",
    "    if results_df['error'].isna().sum() > 0:\n",
    "        print(f\"\\nFood detection results:\")\n",
    "        print(f\"Contains food: {results_df['contains_food'].sum()}\")\n",
    "        print(f\"No food: {(~results_df['contains_food']).sum()}\")\n",
    "        print(f\"\\nAverage confidence score: {results_df['food_confidence'].mean():.3f}\")\n",
    "        print(f\"Average processing time: {results_df['processing_time'].mean():.3f} seconds per image\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
