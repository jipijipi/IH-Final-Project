{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food in Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import yaml\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse, parse_qs, quote\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what is food\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time consuming : \n",
    "#get time periods\n",
    "#deal with missing data\n",
    "#dl more images\n",
    "#retrain clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: #get time periods + decades\n",
    "#TODO: calculate proportions\n",
    "#TODO: retrain CLiP for recognition of the new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_config(config_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load configuration from YAML file.\n",
    "    \n",
    "    Args:\n",
    "        config_path: Path to YAML configuration file\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing configuration settings\n",
    "    \"\"\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_datetime(series: pd.Series, value_type) -> pd.Series:\n",
    "    \"\"\"Convert series to datetime format.\"\"\"\n",
    "    series = pd.to_datetime(series, errors='coerce')\n",
    "    if value_type == 'year':\n",
    "        return pd.to_numeric(series.dt.year, downcast='integer', errors='coerce')\n",
    "    return series\n",
    "\n",
    "def clean_categorical(series: pd.Series, categories = None) -> pd.Series:\n",
    "    \"\"\"Convert series to categorical format with optional categories.\"\"\"\n",
    "    if categories:\n",
    "        return pd.Categorical(series, categories=categories, ordered=False )\n",
    "    return series.astype('category')\n",
    "\n",
    "\n",
    "def extract_wikidata_id(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Extract the Wikidata ID from a series of URLs.\"\"\"\n",
    "    return series.str.extract(r'(Q\\d+)', expand=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_column(series: pd.Series, dtype: str, value_type: str = None, categories = None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Process a single column according to its configuration.\n",
    "    \n",
    "    Args:\n",
    "        series: Column data to process\n",
    "        dtype: Target data type\n",
    "        categories: Optional list of categories for categorical data\n",
    "    \n",
    "    Returns:\n",
    "        Processed column data\n",
    "    \"\"\"\n",
    "    if value_type == 'wikidata_url':\n",
    "        return extract_wikidata_id(series)\n",
    "    \n",
    "    if dtype == 'datetime64[ns]':\n",
    "        return clean_datetime(series, value_type)\n",
    "    elif dtype == 'category':\n",
    "        return clean_categorical(series, categories)\n",
    "    else:\n",
    "        return series.astype(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_process_dataset(\n",
    "    source_path: str,\n",
    "    columns_config: dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and process a single dataset according to configuration.\n",
    "    \n",
    "    Args:\n",
    "        source_path: Path to source CSV file\n",
    "        columns_config: Configuration for columns\n",
    "        dataset_name: Name of the dataset for specific processing\n",
    "    \n",
    "    Returns:\n",
    "        Processed DataFrame\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_csv(source_path)\n",
    "    \n",
    "    # Rename columns\n",
    "    column_mappings = {\n",
    "        config['original_name']: col_name\n",
    "        for col_name, config in columns_config.items()\n",
    "        if 'original_name' in config\n",
    "    }\n",
    "    df = df.rename(columns=column_mappings)\n",
    "    \n",
    "    # Select configured columns\n",
    "    df = df[list(columns_config.keys())]\n",
    "    \n",
    "    # Process each column\n",
    "    for column, config in columns_config.items():\n",
    "        df[column] = process_column(\n",
    "            df[column],\n",
    "            config['dtype'],\n",
    "            config.get('value_type'),\n",
    "            config.get('categories')\n",
    "        )\n",
    "    \n",
    "    # Set index if specified\n",
    "    for column, config in columns_config.items():\n",
    "        if config.get('is_index', False):\n",
    "            df = df.drop_duplicates(subset=column, keep='first')\n",
    "            #df = df.set_index(column)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_all_datasets(config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Load and process all datasets defined in configuration.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dict\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of processed DataFrames\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        dataset_name: load_and_process_dataset(\n",
    "            dataset_config['source'],\n",
    "            dataset_config['columns']\n",
    "        )\n",
    "        for dataset_name, dataset_config in config.items()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_512px_thumbnail(url):\n",
    "    \"\"\"\n",
    "    Transform a Wikimedia Commons Special:FilePath URL into its 512px thumbnail version.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL in format: http://commons.wikimedia.org/wiki/Special:FilePath/Filename.jpg\n",
    "        \n",
    "    Returns:\n",
    "        str: The 512px thumbnail URL or None if the URL is null\n",
    "    \n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return None\n",
    "    \n",
    "    # Extract the filename from the URL\n",
    "    filename = url.split('/')[-1]\n",
    "    \n",
    "    # Construct the 512px thumbnail URL\n",
    "    thumbnail_url = f\"https://commons.wikimedia.org/w/index.php?title=Special:Redirect/file/{filename}&width=512\"\n",
    "    \n",
    "    return thumbnail_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from YAML file\n",
    "config = load_config('config.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = load_all_datasets(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load correspondance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondance_data = all_data['ids']\n",
    "correspondance_data.drop_duplicates(inplace=True)\n",
    "correspondance_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load paintings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_data = all_data['paintings']\n",
    "paintings_data['image_url'] = paintings_data['image_url'].apply(lambda x: get_512px_thumbnail(x) if pd.notna(x) else x)\n",
    "paintings_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load locations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_data = all_data['locations']\n",
    "locations_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load authors data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_data = all_data['authors']\n",
    "authors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ML food data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_words = all_data['food_words']\n",
    "food_words['food_word_detected'] = food_words.select_dtypes(include='int').sum(axis=1) > 0\n",
    "food_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_found = all_data['food_found']\n",
    "food_found['food_image_detected'] = food_found['predictions'].apply(lambda x: len(x) > 3)\n",
    "food_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = correspondance_data.merge(paintings_data, on='painting_id', how='inner')\n",
    "merged_df = merged_df.merge(authors_data, on='author_id', how='left')\n",
    "merged_df = merged_df.merge(locations_data, on='location_id', how='left')\n",
    "merged_df = merged_df.merge(food_words, on='painting_id', how='left')\n",
    "merged_df = merged_df.merge(food_found, on='painting_id', how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop_duplicates(subset='painting_id', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['food_detected'] = (merged_df['food_word_detected'] | merged_df['food_image_detected']).astype(int)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[merged_df['image_path'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df['food_detected'].value_counts())\n",
    "print(merged_df['food_word_detected'].value_counts())\n",
    "print(merged_df['food_image_detected'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(merged_df[['creation_date','date_of_birth']])\n",
    "display(merged_df[['creation_date','date_of_birth']].describe())\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_year(input_str):\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    # Check if the input string has at least 4 characters and can be converted to an integer\n",
    "    if isinstance(input_str, str) and len(input_str) >= 4:\n",
    "        try:\n",
    "            year = int(input_str[:4])\n",
    "            if year > current_year:\n",
    "                return np.nan\n",
    "            return year\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "merged_df['creation_date'] = merged_df['creation_date'].apply(extract_year)\n",
    "merged_df['date_of_birth'] = merged_df['date_of_birth'].apply(extract_year)\n",
    "\n",
    "\n",
    "display(merged_df[['creation_date','date_of_birth']])\n",
    "display(merged_df[['creation_date','date_of_birth']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing creation year when possible\n",
    "# Calculate the age of the painter at the time of painting\n",
    "merged_df['painter_age_at_painting'] = merged_df['creation_date'] - merged_df['date_of_birth']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(merged_df[['painter', 'creation_date', 'date_of_birth', 'painter_age_at_painting']])\n",
    "\n",
    "# Calculate the average painter_age_at_painting for each painter\n",
    "avg_painter_age = merged_df['painter_age_at_painting'].mean().astype(int)\n",
    "\n",
    "merged_df['painter_age_at_painting'].fillna(avg_painter_age, inplace=True)\n",
    "#merged_df.dropna(subset=['creation_date', 'date_of_birth'], how='all', inplace=True)\n",
    "\n",
    "# Fill missing creation_date with date_of_birth + avg_painter_age\n",
    "merged_df['creation_date'].fillna(merged_df['date_of_birth'] + avg_painter_age, inplace=True)\n",
    "\n",
    "display(merged_df[['painter', 'creation_date', 'date_of_birth', 'painter_age_at_painting']])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['painter'].fillna('Unknown Artist', inplace=True)\n",
    "merged_df['author_country'].fillna('Unknown Country', inplace=True)\n",
    "merged_df['location_country'].fillna('Unknown Country', inplace=True)\n",
    "merged_df['location_name'].fillna('Unknown Location', inplace=True)\n",
    "\n",
    "merged_df['author_gender'] = merged_df['author_gender'].astype('category')\n",
    "merged_df['author_gender'] = merged_df['author_gender'].cat.set_categories(['male', 'female'])\n",
    "merged_df['author_gender'].fillna('male', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a column with decades\n",
    "merged_df['decade'] = (merged_df['creation_date'] // 10) * 10\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(merged_df[['painter', 'creation_date', 'decade']])\n",
    "print(merged_df['decade'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['location_country'] = merged_df['location_country'].replace('German Reich', 'Germany')\n",
    "merged_df['author_country'] = merged_df['author_country'].replace('German Reich', 'Germany')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_period(decade):\n",
    "    if decade < 1000:\n",
    "        return \"Antiquity\"\n",
    "    elif 1000 <= decade < 1400:\n",
    "        return \"Medieval\"\n",
    "    elif 1400 <= decade < 1500:\n",
    "        return \"Early Renaissance\"\n",
    "    elif 1500 <= decade < 1600:\n",
    "        return \"High Renaissance and Mannerism\"\n",
    "    elif 1600 <= decade < 1700:\n",
    "        return \"Baroque\"\n",
    "    elif 1700 <= decade < 1780:\n",
    "        return \"Rococo\"\n",
    "    elif 1780 <= decade < 1850:\n",
    "        return \"Neoclassicism and Romanticism\"\n",
    "    elif 1850 <= decade < 1900:\n",
    "        return \"Realism and Impressionism\"\n",
    "    elif 1900 <= decade < 1945:\n",
    "        return \"Modern Art\"\n",
    "    elif 1945 <= decade < 1970:\n",
    "        return \"Post-War and Abstract Expressionism\"\n",
    "    elif 1970 <= decade < 2000:\n",
    "        return \"Contemporary Art\"\n",
    "    else:\n",
    "        return \"Contemporary and Digital Art\"\n",
    "\n",
    "\n",
    "\n",
    "merged_df['time_period'] = merged_df['decade'].apply(classify_period)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add gdp and pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_df = pd.read_csv('data/gdp_pop_decades.csv')\n",
    "eco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(\n",
    "    eco_df,\n",
    "    on='decade',\n",
    "    how='left'  # Keep all artwork records, even if no economic data exists\n",
    ")\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize 'gdppc' and 'pop' columns\n",
    "merged_df[['gdppc_normalized', 'pop_normalized']] = scaler.fit_transform(merged_df[['gdppc', 'pop']])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(merged_df[['gdppc', 'gdppc_normalized', 'pop', 'pop_normalized']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export for clip\n",
    "clip_train = merged_df[['painting_id','image_path', 'food_word_detected']]\n",
    "clip_train = clip_train[clip_train['food_word_detected'] == 1]\n",
    "clip_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_with_food = merged_df[merged_df['image_url'].isna() == False]\n",
    "paintings_with_food = paintings_with_food[['title', 'painter', 'creation_date', 'author_gender', 'author_country', 'location_name', 'location_country', 'time_period', 'image_path', 'image_url', 'coordinates','food_detected','decade','gdppc','pop', 'gdppc_normalized', 'pop_normalized']]\n",
    "paintings_with_food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_with_food.to_csv('data/paintings_with_food.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by decade and calculate the proportion of food_detected\n",
    "food_by_decade = merged_df.groupby('decade')['food_detected'].agg(artwork_count='count', food_related_sum='sum').reset_index()\n",
    "food_by_decade['proportion_food_detected'] = food_by_decade['food_related_sum'] / food_by_decade['artwork_count']\n",
    "# Merge normalized GDP and population data\n",
    "food_by_decade = food_by_decade.merge(\n",
    "    merged_df[['decade', 'gdppc_normalized', 'pop_normalized']].drop_duplicates(),\n",
    "    on='decade',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Filter the DataFrame to include only records from 1250 to 2000\n",
    "food_by_decade = food_by_decade[(food_by_decade['decade'] >= 1250) & (food_by_decade['decade'] <= 2000)]\n",
    "# Display the resulting DataFrame\n",
    "food_by_decade.to_csv('data/food_by_decade_analysis.csv', index=False)\n",
    "food_by_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "# Creating the DataFrame directly since we have the data as a string\n",
    "data = food_by_decade\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "correlation = data['proportion_food_detected'].corr(data['gdppc_normalized'])\n",
    "correlation_pvalue = stats.pearsonr(data['proportion_food_detected'], data['gdppc_normalized'])\n",
    "\n",
    "# Create a scatter plot with regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=data, \n",
    "            x='proportion_food_detected', \n",
    "            y='gdppc_normalized',\n",
    "            scatter_kws={'alpha':0.5},\n",
    "            line_kws={'color': 'red'})\n",
    "\n",
    "plt.title('Correlation between Food-Related Artwork Proportion and GDP per Capita')\n",
    "plt.xlabel('Proportion of Food-Related Artwork')\n",
    "plt.ylabel('Normalized GDP per Capita')\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = {\n",
    "    'Pearson Correlation': correlation,\n",
    "    'P-value': correlation_pvalue[1],\n",
    "    'Sample Size': len(data),\n",
    "    'Mean Food Proportion': data['proportion_food_detected'].mean(),\n",
    "    'Mean GDP per Capita': data['gdppc_normalized'].mean(),\n",
    "}\n",
    "\n",
    "print(\"\\nCorrelation Analysis Results:\")\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Additional analysis: Rolling correlation\n",
    "window_size = 10\n",
    "rolling_corr = data.rolling(window=window_size).corr()[['proportion_food_detected', 'gdppc_normalized']]['gdppc_normalized'].dropna()\n",
    "\n",
    "\"\"\" plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['decade'][window_size-1:len(rolling_corr)+window_size-1], rolling_corr, label='Rolling Correlation')\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "plt.title(f'Rolling Correlation (Window Size: {window_size} decades)')\n",
    "plt.xlabel('Decade')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.legend() \"\"\"\n",
    "\n",
    "# Show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "# Step 2: Calculate the Pearson correlation coefficient and p-value\n",
    "x = df['gdppc_normalized']\n",
    "y = df['proportion_food_detected']\n",
    "\n",
    "corr_coeff, p_value = pearsonr(x, y)\n",
    "print(f\"Pearson correlation coefficient: {corr_coeff}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Step 3: Visualize the data with a scatter plot and a regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, color='blue', label='Data points')\n",
    "\n",
    "# Fit a regression line\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b, color='red', label='Regression line')\n",
    "\n",
    "plt.xlabel('GDP per Capita (Normalized)')\n",
    "plt.ylabel('Proportion of Food Artworks')\n",
    "plt.title('Correlation between GDP per Capita and Proportion of Food Artworks')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Interpret the results\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant correlation between GDP per capita and the proportion of food artworks.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant correlation between GDP per capita and the proportion of food artworks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paintings_with_food.value_counts())\n",
    "print(merged_df['image_path'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_with_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df[merged_df['food_detected'] == True]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gdp analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count paintings per author country\n",
    "paintings_per_country = paintings_with_food['author_country'].value_counts().reset_index()\n",
    "paintings_per_country.columns = ['Author Country', 'Number of Paintings']\n",
    "\n",
    "# Create bar chart\n",
    "fig1 = px.bar(paintings_per_country, \n",
    "              x='Author Country', \n",
    "              y='Number of Paintings',\n",
    "              title='Number of Paintings per Author Country',\n",
    "              labels={'Author Country': 'Country', 'Number of Paintings': 'Paintings'})\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count authors by gender\n",
    "gender_counts = paintings_with_food['author_gender'].value_counts().reset_index()\n",
    "gender_counts.columns = ['Gender', 'Count']\n",
    "\n",
    "# Create pie chart\n",
    "fig2 = px.pie(gender_counts, \n",
    "             names='Gender', \n",
    "             values='Count',\n",
    "             title='Gender Distribution of Authors',\n",
    "             hole=0.3)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in 'title' column\n",
    "paintings_with_food = paintings_with_food.dropna(subset=['title', 'creation_date'])\n",
    "\n",
    "# Sample 100 random rows from the DataFrame\n",
    "df_subset = paintings_with_food.sample(n=100, random_state=42)  # Use `n` to specify the number of rows you want in the subset\n",
    "\n",
    "# Alternatively, if you want a percentage-based sample (e.g., 10% of the data)\n",
    "df_subset = paintings_with_food.sample(frac=0.1, random_state=42)  # `frac` is the fraction of rows to sample\n",
    "\n",
    "# Now, you can create the plot with this subset\n",
    "fig3 = px.scatter(df_subset, \n",
    "                  x='creation_date', \n",
    "                  y='title',\n",
    "                  #title='Timeline of Paintings Creation Dates (Random Subset)',\n",
    "                  #labels={'creation_date': 'Creation Date', 'title': 'Painting Title'},\n",
    "                  #hover_data=['author_name']\n",
    "                  )\n",
    "fig3.update_yaxes(autorange=\"reversed\")  # Optional: To display earliest at top\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latitude and longitude from coordinates\n",
    "paintings_with_food[['Longitude', 'Latitude']] = paintings_with_food['coordinates'].str.extract(r'Point\\(([-\\d.]+) ([-\\d.]+)\\)', expand=True).astype(float)\n",
    "\n",
    "# Create map\n",
    "fig4 = px.scatter_geo(paintings_with_food,\n",
    "                      lat='Latitude',\n",
    "                      lon='Longitude',\n",
    "                      hover_name='location_name',\n",
    "                      hover_data={'Latitude': False, 'Longitude': False},\n",
    "                      title='Geographical Distribution of Painting Locations',\n",
    "                      projection='natural earth')\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_with_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Count paintings per author\n",
    "paintings_per_author = paintings_with_food['painter'].value_counts().head(10).reset_index()\n",
    "paintings_per_author.columns = ['Painter', 'Number of Paintings']\n",
    "\n",
    "# Create horizontal bar chart\n",
    "fig5 = px.bar(paintings_per_author.sort_values('Number of Paintings'),\n",
    "             x='Number of Paintings',\n",
    "             y='Painter',\n",
    "             orientation='h',\n",
    "             #title='Top 10 Authors by Number of Paintings',\n",
    "             #labels={'Number of Paintings': 'Paintings', 'Painter': 'Author'}\n",
    "             )\n",
    "fig5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count paintings with and without food\n",
    "food_counts = merged_df['food_detected'].value_counts().reset_index()\n",
    "food_counts.columns = ['food_detected', 'Count']\n",
    "food_counts['food_detected'] = food_counts['food_detected'].map({True: 'Contains Food', False: 'No Food'})\n",
    "\n",
    "# Create donut chart\n",
    "fig6 = px.pie(food_counts, \n",
    "             names='Contains Food', \n",
    "             values='Count',\n",
    "             title='Paintings Containing Food vs. Not Containing Food',\n",
    "             hole=0.4)\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "# Split the strings into individual words\n",
    "all_food_words = list(itertools.chain.from_iterable(df['food_words'].dropna().apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))))\n",
    "food_counter = Counter(all_food_words).most_common(10)\n",
    "\n",
    "# Create dataframe for plotting\n",
    "food_df = pd.DataFrame(food_counter, columns=['Food Item', 'Frequency'])\n",
    "\n",
    "# Create bar chart\n",
    "fig7 = px.bar(food_df, \n",
    "             x='Food Item', \n",
    "             y='Frequency',\n",
    "             title='Frequency of Different Food Items in Paintings',\n",
    "             labels={'Food Item': 'Food Item', 'Frequency': 'Count'})\n",
    "fig7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing data\n",
    "scatter_df = df.dropna(subset=['date_of_birth', 'creation_date'])\n",
    "\n",
    "# Create scatter plot\n",
    "fig8 = px.scatter(scatter_df, \n",
    "                  x='date_of_birth', \n",
    "                  y='creation_date',\n",
    "                  trendline='ols',\n",
    "                  title=\"Authors' Birth Years vs. Painting Creation Years\",\n",
    "                  labels={'date_of_birth': 'Author Birth Year', 'creation_date': 'Creation Year'},\n",
    "                  hover_data=['painter', 'title'])\n",
    "fig8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a very small subset for testing\n",
    "# Drop rows with missing data\n",
    "scatter_df = df.dropna(subset=['date_of_birth', 'creation_date'])\n",
    "df_subset = scatter_df[['creation_date', 'title']].head(100)\n",
    "fig3 = px.scatter(df_subset, \n",
    "                  x='creation_date', \n",
    "                  y='title',\n",
    "                  title='Test Plot of Paintings Creation Dates')\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count paintings per location country\n",
    "paintings_per_location_country = df['location_country'].value_counts().reset_index()\n",
    "paintings_per_location_country.columns = ['Location Country', 'Number of Paintings']\n",
    "\n",
    "# Create treemap\n",
    "fig9 = px.treemap(paintings_per_location_country, \n",
    "                 path=['Location Country'], \n",
    "                 values='Number of Paintings',\n",
    "                 title='Distribution of Paintings by Location Country')\n",
    "fig9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def get_wikimedia_thumbnail(filename, width=200):\n",
    "    # Calculate the MD5 hash of the filename\n",
    "    md5_hash = hashlib.md5(filename.encode('utf-8')).hexdigest()\n",
    "    \n",
    "    # Construct the thumbnail URL\n",
    "    url = f\"https://upload.wikimedia.org/wikipedia/commons/thumb/{md5_hash[0]}/{md5_hash[:2]}/{filename}/{width}px-{filename}\"\n",
    "    \n",
    "    return url\n",
    "\n",
    "\n",
    "\n",
    "# Ensure there are no missing values in hover_data columns\n",
    "gallery = df[['creation_date', 'title', 'painter', 'location_name', 'filename']].dropna().head(10)\n",
    "gallery['url'] = gallery['filename'].apply(get_wikimedia_thumbnail)\n",
    "\n",
    "\n",
    "fig10 = px.scatter(gallery, \n",
    "                   x='creation_date', \n",
    "                   y='title',\n",
    "                   hover_data=['painter', 'location_name', 'url'],\n",
    "                   title='Interactive Gallery of Paintings',\n",
    "                   labels={'creation_date': 'Creation Date', 'title': 'Painting Title'},\n",
    "                   template='plotly_white')\n",
    "\n",
    "# Add images as hover\n",
    "fig10.update_traces(marker=dict(size=12,\n",
    "                                 color='LightSkyBlue'),\n",
    "                   selector=dict(mode='markers'))\n",
    "\n",
    "fig10.update_layout(\n",
    "    hovermode='closest',\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update hovertemplate to include image\n",
    "fig10.update_traces(\n",
    "    hovertemplate=\"<b>%{y}</b><br><br>\" +\n",
    "                  \"Author: %{customdata[0]}<br>\" +\n",
    "                  \"Location: %{customdata[1]}<br>\" +\n",
    "                  \"<br><img src='%{customdata[2]}' width='150' height='150'><br>\" +\n",
    "                  \"<extra></extra>\"\n",
    ")\n",
    "\n",
    "fig10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Group by year and calculate proportions\n",
    "food_over_time = merged_df.groupby('creation_date')['contains_food'].agg(['count', 'sum']).reset_index()\n",
    "food_over_time['Proportion with Food'] = food_over_time['sum'] / food_over_time['count']\n",
    "\n",
    "# Create line chart\n",
    "fig2 = px.line(food_over_time, \n",
    "               x='creation_date', \n",
    "               y='Proportion with Food',\n",
    "               title='Proportion of Paintings Containing Food Over Time',\n",
    "               labels={'creation_date': 'Year', 'Proportion with Food': 'Proportion'},\n",
    "               markers=True)\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Expand food_words into separate rows\n",
    "df_food = df.explode('food_words').dropna(subset=['food_words'])\n",
    "\n",
    "# Count food items per author country\n",
    "food_country = df_food.groupby(['author_country', 'food_words']).size().reset_index(name='Count')\n",
    "\n",
    "# Create stacked bar chart\n",
    "fig3 = px.bar(food_country, \n",
    "              x='author_country', \n",
    "              y='Count', \n",
    "              color='food_words',\n",
    "              title='Distribution of Food Items by Author Country',\n",
    "              labels={'author_country': 'Author Country', 'food_words': 'Food Item', 'Count': 'Count'},\n",
    "              barmode='stack')\n",
    "\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter paintings that contain food\n",
    "df_food = df[df['contains_food'] == True]\n",
    "\n",
    "# Create heatmap\n",
    "fig4 = px.density_mapbox(df_food, \n",
    "                         lat='Latitude', \n",
    "                         lon='Longitude',\n",
    "                         radius=10,\n",
    "                         center=dict(lat=20, lon=0),\n",
    "                         zoom=1,\n",
    "                         mapbox_style='stamen-terrain',\n",
    "                         title='Geographical Heatmap of Food-Containing Paintings')\n",
    "\n",
    "fig4.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of food items per painting\n",
    "merged_df['num_food_items'] = merged_df['food_words'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Group by author and calculate average\n",
    "avg_food_per_author = merged_df.groupby('painter')['num_food_items'].mean().reset_index()\n",
    "avg_food_per_author = avg_food_per_author.sort_values('num_food_items', ascending=False).head(10)\n",
    "\n",
    "# Create bar chart\n",
    "fig6 = px.bar(avg_food_per_author, \n",
    "              x='painter', \n",
    "              y='num_food_items',\n",
    "              title='Average Number of Food Items per Painting by Author',\n",
    "              labels={'painter': 'Author', 'num_food_items': 'Average Number of Food Items'},\n",
    "              color='num_food_items',\n",
    "              color_continuous_scale='Oranges')\n",
    "\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "df_food = df.explode('food_words').dropna(subset=['food_words'])\n",
    "food_location = df_food.groupby(['food_words', 'location_country']).size().reset_index(name='Count')\n",
    "\n",
    "# Select top 10 food items\n",
    "top_food = food_location['food_words'].value_counts().head(10).index\n",
    "food_location_top = food_location[food_location['food_words'].isin(top_food)]\n",
    "\n",
    "# Create bubble chart\n",
    "fig7 = px.scatter(food_location_top, \n",
    "                  x='location_country', \n",
    "                  y='food_words',\n",
    "                  size='Count',\n",
    "                  color='food_words',\n",
    "                  title='Correlation Between Specific Food Items and Painting Locations',\n",
    "                  labels={'location_country': 'Location Country', 'food_words': 'Food Item', 'Count': 'Number of Paintings'},\n",
    "                  hover_name='food_words',\n",
    "                  size_max=40)\n",
    "\n",
    "fig7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare pivot table\n",
    "food_country_pivot = df_food.groupby(['author_country', 'food_words']).size().reset_index(name='Count')\n",
    "food_country_pivot = food_country_pivot.pivot(index='food_words', columns='author_country', values='Count').fillna(0)\n",
    "\n",
    "# Create heatmap\n",
    "fig8 = px.imshow(food_country_pivot,\n",
    "                labels=dict(x=\"Author Country\", y=\"Food Item\", color=\"Count\"),\n",
    "                title=\"Heatmap of Food Item Frequencies Across Author Countries\",\n",
    "                aspect=\"auto\",\n",
    "                color_continuous_scale='Viridis')\n",
    "\n",
    "fig8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "df['num_food_items'] = df['food_words'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Create box plot\n",
    "fig9 = px.box(df, \n",
    "             x='gender', \n",
    "             y='num_food_items',\n",
    "             title='Number of Food Items in Paintings by Author Gender',\n",
    "             labels={'gender': 'Author Gender', 'num_food_items': 'Number of Food Items'},\n",
    "             color='gender')\n",
    "\n",
    "fig9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "df_food = df.explode('food_words').dropna(subset=['food_words']).head(30)\n",
    "\n",
    "# Define unique labels\n",
    "authors = df_food['painter'].unique().tolist()\n",
    "foods = df_food['food_words'].unique().tolist()\n",
    "locations = df_food['location_name'].unique().tolist()\n",
    "\n",
    "labels = authors + foods + locations\n",
    "\n",
    "# Create source and target indices\n",
    "df_food['source'] = df_food['painter'].apply(lambda x: labels.index(x))\n",
    "df_food['target_food'] = df_food['food_words'].apply(lambda x: labels.index(x) + len(authors))\n",
    "df_food['target_location'] = df_food['location_name'].apply(lambda x: labels.index(x) + len(authors) + len(foods))\n",
    "\n",
    "# Create links for authors to food\n",
    "links_auth_food = df_food.groupby(['source', 'target_food']).size().reset_index(name='value')\n",
    "\n",
    "# Create links for food to locations\n",
    "links_food_loc = df_food.groupby(['target_food', 'target_location']).size().reset_index(name='value')\n",
    "\n",
    "# Combine links\n",
    "links = pd.concat([\n",
    "    links_auth_food.rename(columns={'target_food': 'target'}),\n",
    "    links_food_loc.rename(columns={'target_location': 'target'})\n",
    "], ignore_index=True)\n",
    "\n",
    "# Create Sankey diagram\n",
    "fig10 = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=labels,\n",
    "        color=\"blue\"\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=links['source'],\n",
    "        target=links['target'],\n",
    "        value=links['value']\n",
    "    ))])\n",
    "\n",
    "fig10.update_layout(title_text=\"Sankey Diagram: Authors → Food Items → Locations\", font_size=10)\n",
    "fig10.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
