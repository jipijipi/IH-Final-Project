{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food in Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('data/paintings_with_descriptions.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------------------- Configuration ----------------------------\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "\n",
    "# Wikimedia Commons API endpoint\n",
    "API_ENDPOINT = \"https://commons.wikimedia.org/w/api.php\"\n",
    "\n",
    "# Directory to save downloaded images\n",
    "OUTPUT_DIR = f'img/img_{IMG_WIDTH}'\n",
    "\n",
    "# File to store checkpoint information\n",
    "CHECKPOINT_FILE = \"data/checkpoints/download_checkpoint.txt\"\n",
    "\n",
    "# Number of concurrent threads for downloading\n",
    "MAX_WORKERS = 3  # Adjust based on your network and Wikimedia's rate limits\n",
    "\n",
    "# Batch size for API requests\n",
    "BATCH_SIZE = 30  # Number of filenames per batch API request\n",
    "\n",
    "# User-Agent header to identify your script (replace with your details)\n",
    "USER_AGENT = \"IH-final/1.0 (jipijipijipi@gmail.com)\"\n",
    "\n",
    "# Timeout settings for HTTP requests\n",
    "API_TIMEOUT = 30  # seconds\n",
    "DOWNLOAD_TIMEOUT = 60  # seconds\n",
    "\n",
    "# Maximum number of retries for failed downloads\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# Delay between API requests to respect rate limits\n",
    "API_DELAY = 0.5  # seconds\n",
    "\n",
    "# ---------------------------- Setup ----------------------------\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load your dataframe\n",
    "# The dataframe should have a column named 'link' with Wikimedia URLs\n",
    "image_links = df['image_url'].tolist()\n",
    "\n",
    "\n",
    "# Load checkpoint\n",
    "if os.path.exists(CHECKPOINT_FILE):\n",
    "    with open(CHECKPOINT_FILE, 'r') as f:\n",
    "        downloaded = set(line.strip() for line in f)\n",
    "else:\n",
    "    downloaded = set()\n",
    "\n",
    "# Function to extract the file name from the URL\n",
    "def extract_filename(url):\n",
    "    parsed = urllib.parse.urlparse(url)\n",
    "    # First decoding: %2520 -> %20\n",
    "    first_decode = urllib.parse.unquote(parsed.path)\n",
    "    # Second decoding: %20 -> space\n",
    "    second_decode = urllib.parse.unquote(first_decode)\n",
    "    filename = os.path.basename(second_decode)\n",
    "    # Replace spaces with underscores as per MediaWiki API requirements\n",
    "    filename = filename.replace(' ', '_')\n",
    "    return filename\n",
    "\n",
    "# Function to split iterable into chunks of size 'size'\n",
    "def chunked_iterable(iterable, size):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        try:\n",
    "            chunk = [next(it) for _ in range(size)]\n",
    "        except StopIteration:\n",
    "            chunk = []\n",
    "        if not chunk:\n",
    "            break\n",
    "        yield chunk\n",
    "        if len(chunk) < size:\n",
    "            break\n",
    "\n",
    "# ---------------------------- Helper Functions ----------------------------\n",
    "\n",
    "def fetch_thumbnail_urls(filenames):\n",
    "    \"\"\"\n",
    "    Fetch thumbnail URLs for a batch of filenames using Wikimedia API.\n",
    "\n",
    "    :param filenames: List of filenames\n",
    "    :return: Dictionary mapping filename to thumbnail URL or full URL\n",
    "    \"\"\"\n",
    "    titles = '|'.join([f'File:{filename}' for filename in filenames])\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'titles': titles,\n",
    "        'prop': 'imageinfo',\n",
    "        'iiprop': 'url',\n",
    "        'iiurlwidth': '100',  # Adjusted to a minimal valid width\n",
    "        'format': 'json',\n",
    "        'formatversion': '2'\n",
    "    }\n",
    "    headers = {\n",
    "        'User-Agent': USER_AGENT\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(API_ENDPOINT, params=params, headers=headers, timeout=API_TIMEOUT)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        result = {}\n",
    "        pages = data.get('query', {}).get('pages', [])\n",
    "        for page in pages:\n",
    "            title = page.get('title', '')\n",
    "            filename = title.replace('File:', '')\n",
    "            imageinfo = page.get('imageinfo', [])\n",
    "            if imageinfo:\n",
    "                # Prefer 'thumburl' if available, else fallback to 'url'\n",
    "                thumb_url = imageinfo[0].get('thumburl')\n",
    "                if not thumb_url:\n",
    "                    # If thumburl is not available, use the full image URL\n",
    "                    thumb_url = imageinfo[0].get('url')\n",
    "                result[filename] = thumb_url\n",
    "            else:\n",
    "                result[filename] = None\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during fetching thumbnail URLs: {e}\")\n",
    "        return {}\n",
    "\n",
    "def download_image(session, url, filename):\n",
    "    \"\"\"\n",
    "    Download an image from the given URL and save it to the output directory.\n",
    "\n",
    "    :param session: requests.Session object\n",
    "    :param url: URL of the image to download\n",
    "    :param filename: Filename to save the image as\n",
    "    :return: Boolean indicating success or failure\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        print(f\"No URL provided for {filename}. Skipping download.\")\n",
    "        return False\n",
    "\n",
    "    image_path = os.path.join(OUTPUT_DIR, filename)\n",
    "\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            response = session.get(url, timeout=DOWNLOAD_TIMEOUT)\n",
    "            response.raise_for_status()\n",
    "            with open(image_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {filename} (Attempt {attempt}/{MAX_RETRIES}): {e}\")\n",
    "            time.sleep(1)  # Wait before retrying\n",
    "    print(f\"Failed to download {filename} after {MAX_RETRIES} attempts.\")\n",
    "    return False\n",
    "\n",
    "def update_checkpoint(filename):\n",
    "    \"\"\"\n",
    "    Append the successfully downloaded filename to the checkpoint file.\n",
    "\n",
    "    :param filename: Filename to add to checkpoint\n",
    "    \"\"\"\n",
    "    with open(CHECKPOINT_FILE, 'a') as f:\n",
    "        f.write(f\"{filename}\\n\")\n",
    "\n",
    "# ---------------------------- Main Function ----------------------------\n",
    "\n",
    "\n",
    "df['filename'] = df['image_url'].apply(extract_filename)\n",
    "filenames = df['filename'].tolist()\n",
    "filenames_to_download = [fn for fn in filenames if fn not in downloaded]\n",
    "\n",
    "total_images = len(filenames_to_download)\n",
    "print(f\"Total images to download: {total_images}\")\n",
    "\n",
    "# Initialize a requests session for HTTP connections\n",
    "session = requests.Session()\n",
    "session.headers.update({'User-Agent': USER_AGENT})\n",
    "\n",
    "# Initialize ThreadPoolExecutor for parallel downloads\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    # Process in batches\n",
    "    for batch_num, batch in enumerate(chunked_iterable(filenames_to_download, BATCH_SIZE), start=1):\n",
    "        print(f\"Processing batch {batch_num} with {len(batch)} images...\")\n",
    "        thumb_urls = fetch_thumbnail_urls(batch)\n",
    "\n",
    "        # Prepare download tasks\n",
    "        tasks = []\n",
    "        for filename, url in thumb_urls.items():\n",
    "            if url:\n",
    "                tasks.append((filename, url))\n",
    "            else:\n",
    "                print(f\"No thumbnail URL found for {filename, url}. Skipping.\")\n",
    "\n",
    "        if not tasks:\n",
    "            print(f\"No downloadable URLs found in batch {batch_num}. Skipping to next batch.\")\n",
    "            continue\n",
    "\n",
    "        # Use tqdm for progress bar\n",
    "        with tqdm(total=len(tasks), desc=f\"Batch {batch_num}\", unit=\"image\") as pbar:\n",
    "            future_to_filename = {\n",
    "                executor.submit(download_image, session, url, filename): filename\n",
    "                for filename, url in tasks\n",
    "            }\n",
    "            for future in as_completed(future_to_filename):\n",
    "                filename = future_to_filename[future]\n",
    "                try:\n",
    "                    success = future.result()\n",
    "                    if success:\n",
    "                        update_checkpoint(filename)\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error downloading {filename}: {e}\")\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "\n",
    "        # Optional: Delay between batches to respect API rate limits\n",
    "        time.sleep(API_DELAY)\n",
    "\n",
    "print(\"All downloads completed.\")   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
