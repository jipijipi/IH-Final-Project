{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def setup_model():\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    base_model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    for param in base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    num_features = base_model.fc.in_features\n",
    "    base_model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(256, 13),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    return base_model.to(device), device\n",
    "\n",
    "def load_and_transform_image(image_path, transform):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        return transform(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def prepare_batch_data(image_paths, labels, transform, device):\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    for img_path, label in zip(image_paths, labels):\n",
    "        img_tensor = load_and_transform_image(img_path, transform)\n",
    "        if img_tensor is not None:\n",
    "            batch_images.append(img_tensor)\n",
    "            batch_labels.append(label)\n",
    "    \n",
    "    if not batch_images:\n",
    "        return None, None\n",
    "    \n",
    "    return (torch.stack(batch_images).to(device), \n",
    "            torch.tensor(batch_labels, dtype=torch.float32).to(device))\n",
    "\n",
    "def train_one_epoch(model, data_df, food_categories, optimizer, criterion, \n",
    "                   device, batch_size=16):  # Reduced batch size for M2\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for start_idx in tqdm(range(0, len(data_df), batch_size)):\n",
    "        batch_df = data_df.iloc[start_idx:start_idx + batch_size]\n",
    "        \n",
    "        batch_images = batch_df['image_path'].tolist()\n",
    "        batch_labels = batch_df[food_categories].values.tolist()\n",
    "        \n",
    "        images, labels = prepare_batch_data(batch_images, batch_labels, transform, device)\n",
    "        if images is None:\n",
    "            continue\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        all_preds.extend(outputs.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        del images, labels, outputs, loss\n",
    "        if device.type == \"mps\":\n",
    "            torch.mps.empty_cache()\n",
    "    \n",
    "    all_preds = np.array(all_preds) > 0.5\n",
    "    all_labels = np.array(all_labels)\n",
    "    accuracy = np.mean((all_preds == all_labels).astype(np.float32))\n",
    "    \n",
    "    return total_loss / num_batches if num_batches > 0 else float('inf'), accuracy\n",
    "\n",
    "def validate(model, data_df, food_categories, criterion, device, batch_size=16):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start_idx in range(0, len(data_df), batch_size):\n",
    "            batch_df = data_df.iloc[start_idx:start_idx + batch_size]\n",
    "            \n",
    "            batch_images = batch_df['image_path'].tolist()\n",
    "            batch_labels = batch_df[food_categories].values.tolist()\n",
    "            \n",
    "            images, labels = prepare_batch_data(batch_images, batch_labels, transform, device)\n",
    "            if images is None:\n",
    "                continue\n",
    "                \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Free up memory\n",
    "            del images, labels, outputs, loss\n",
    "            if device.type == \"mps\":\n",
    "                torch.mps.empty_cache()\n",
    "    \n",
    "    all_preds = np.array(all_preds) > 0.5\n",
    "    all_labels = np.array(all_labels)\n",
    "    accuracy = np.mean((all_preds == all_labels).astype(np.float32))\n",
    "    \n",
    "    return total_loss / num_batches if num_batches > 0 else float('inf'), accuracy\n",
    "\n",
    "def predict(image_path, model, device):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    img_tensor = load_and_transform_image(image_path, transform)\n",
    "    if img_tensor is None:\n",
    "        return None\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor.unsqueeze(0).to(device))\n",
    "        \n",
    "    return outputs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "food_categories = ['fruit', 'bread', 'cookware', 'seafood', 'wine', \n",
    "                    'meal', 'cheese', 'meat', 'food', 'beverage', \n",
    "                    'dairy', 'vegetable', 'dessert']\n",
    "\n",
    "df = pd.read_csv('data/paintings_subset.csv') \n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "model, device = setup_model()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    model.train()\n",
    "    train_loss, train_acc = train_one_epoch(model, train_df, food_categories,\n",
    "                                            optimizer, criterion, device)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate(model, val_df, food_categories,\n",
    "                                criterion, device)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc\n",
    "        }, 'models/best_model_res.pth')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
