{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food in Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the IDs from the SPARQL endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to run the SPARQL query\n",
    "def run_sparql_query(query):\n",
    "    sparql = SPARQLWrapper(wikidata_endpoint_url)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    # Set your user agent to comply with Wikidata's policy\n",
    "    sparql.addCustomHttpHeader('User-Agent', 'MyPaintingDataRetriever/1.0 (jipijipijipi@gmail.com)')\n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        time.sleep(10)  # Wait before retrying\n",
    "        results = sparql.query().convert()\n",
    "    return results\n",
    "\n",
    "# Function to chunk the list into batches\n",
    "def chunk_list(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_endpoint_url = \"https://query.wikidata.org/sparql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from offset 820000\n",
      "Fetching data with OFFSET 820000\n",
      "Fetching data with OFFSET 821000\n",
      "Fetching data with OFFSET 822000\n",
      "Fetching data with OFFSET 823000\n",
      "Fetching data with OFFSET 824000\n",
      "Fetching data with OFFSET 825000\n",
      "Fetching data with OFFSET 826000\n",
      "Fetching data with OFFSET 827000\n",
      "Fetching data with OFFSET 828000\n",
      "Fetching data with OFFSET 829000\n",
      "Checkpoint saved at batch 830\n",
      "Fetching data with OFFSET 830000\n",
      "Fetching data with OFFSET 831000\n",
      "Fetching data with OFFSET 832000\n",
      "Fetching data with OFFSET 833000\n",
      "Fetching data with OFFSET 834000\n",
      "Fetching data with OFFSET 835000\n",
      "Fetching data with OFFSET 836000\n",
      "Fetching data with OFFSET 837000\n",
      "Fetching data with OFFSET 838000\n",
      "Fetching data with OFFSET 839000\n",
      "Checkpoint saved at batch 840\n",
      "Fetching data with OFFSET 840000\n",
      "Fetching data with OFFSET 841000\n",
      "Fetching data with OFFSET 842000\n",
      "Fetching data with OFFSET 843000\n",
      "Fetching data with OFFSET 844000\n",
      "Fetching data with OFFSET 845000\n",
      "Fetching data with OFFSET 846000\n",
      "Fetching data with OFFSET 847000\n",
      "Fetching data with OFFSET 848000\n",
      "Fetching data with OFFSET 849000\n",
      "Checkpoint saved at batch 850\n",
      "Fetching data with OFFSET 850000\n",
      "Fetching data with OFFSET 851000\n",
      "Fetching data with OFFSET 852000\n",
      "Fetching data with OFFSET 853000\n",
      "Fetching data with OFFSET 854000\n",
      "Fetching data with OFFSET 855000\n",
      "Fetching data with OFFSET 856000\n",
      "Fetching data with OFFSET 857000\n",
      "Fetching data with OFFSET 858000\n",
      "Fetching data with OFFSET 859000\n",
      "Checkpoint saved at batch 860\n",
      "Fetching data with OFFSET 860000\n",
      "Fetching data with OFFSET 861000\n",
      "Fetching data with OFFSET 862000\n",
      "Fetching data with OFFSET 863000\n",
      "Fetching data with OFFSET 864000\n",
      "Fetching data with OFFSET 865000\n",
      "Fetching data with OFFSET 866000\n",
      "Fetching data with OFFSET 867000\n",
      "Fetching data with OFFSET 868000\n",
      "Fetching data with OFFSET 869000\n",
      "Checkpoint saved at batch 870\n",
      "Fetching data with OFFSET 870000\n",
      "Fetching data with OFFSET 871000\n",
      "Fetching data with OFFSET 872000\n",
      "Fetching data with OFFSET 873000\n",
      "Fetching data with OFFSET 874000\n",
      "Fetching data with OFFSET 875000\n",
      "Fetching data with OFFSET 876000\n",
      "Fetching data with OFFSET 877000\n",
      "Fetching data with OFFSET 878000\n",
      "Fetching data with OFFSET 879000\n",
      "Checkpoint saved at batch 880\n",
      "Fetching data with OFFSET 880000\n",
      "Fetching data with OFFSET 881000\n",
      "Fetching data with OFFSET 882000\n",
      "Fetching data with OFFSET 883000\n",
      "Fetching data with OFFSET 884000\n",
      "Fetching data with OFFSET 885000\n",
      "Fetching data with OFFSET 886000\n",
      "Fetching data with OFFSET 887000\n",
      "Fetching data with OFFSET 888000\n",
      "Fetching data with OFFSET 889000\n",
      "Checkpoint saved at batch 890\n",
      "Fetching data with OFFSET 890000\n",
      "Fetching data with OFFSET 891000\n",
      "Fetching data with OFFSET 892000\n",
      "Fetching data with OFFSET 893000\n",
      "Fetching data with OFFSET 894000\n",
      "Fetching data with OFFSET 895000\n",
      "Fetching data with OFFSET 896000\n",
      "Fetching data with OFFSET 897000\n",
      "Fetching data with OFFSET 898000\n",
      "Fetching data with OFFSET 899000\n",
      "Checkpoint saved at batch 900\n",
      "Fetching data with OFFSET 900000\n",
      "Fetching data with OFFSET 901000\n",
      "Fetching data with OFFSET 902000\n",
      "Fetching data with OFFSET 903000\n",
      "Fetching data with OFFSET 904000\n",
      "Fetching data with OFFSET 905000\n",
      "Fetching data with OFFSET 906000\n",
      "Fetching data with OFFSET 907000\n",
      "Fetching data with OFFSET 908000\n",
      "Fetching data with OFFSET 909000\n",
      "Checkpoint saved at batch 910\n",
      "Fetching data with OFFSET 910000\n",
      "Fetching data with OFFSET 911000\n",
      "Fetching data with OFFSET 912000\n",
      "Fetching data with OFFSET 913000\n",
      "Fetching data with OFFSET 914000\n",
      "Fetching data with OFFSET 915000\n",
      "Fetching data with OFFSET 916000\n",
      "Fetching data with OFFSET 917000\n",
      "Fetching data with OFFSET 918000\n",
      "Fetching data with OFFSET 919000\n",
      "Checkpoint saved at batch 920\n",
      "Fetching data with OFFSET 920000\n",
      "Fetching data with OFFSET 921000\n",
      "Fetching data with OFFSET 922000\n",
      "Fetching data with OFFSET 923000\n",
      "Fetching data with OFFSET 924000\n",
      "Fetching data with OFFSET 925000\n",
      "Fetching data with OFFSET 926000\n",
      "Fetching data with OFFSET 927000\n",
      "Fetching data with OFFSET 928000\n",
      "Fetching data with OFFSET 929000\n",
      "Checkpoint saved at batch 930\n",
      "Fetching data with OFFSET 930000\n",
      "Fetching data with OFFSET 931000\n",
      "Fetching data with OFFSET 932000\n",
      "Fetching data with OFFSET 933000\n",
      "Fetching data with OFFSET 934000\n",
      "Fetching data with OFFSET 935000\n",
      "Fetching data with OFFSET 936000\n",
      "Fetching data with OFFSET 937000\n",
      "Fetching data with OFFSET 938000\n",
      "Fetching data with OFFSET 939000\n",
      "An error occurred: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
      "\n",
      "Response:\n",
      "b'SPARQL-QUERY: queryStr=\\nSELECT ?item ?author_wikidata ?location_wikidata WHERE {\\n?item wdt:P31 wd:Q3305213.\\nOPTIONAL { ?item wdt:P170 ?author_wikidata. }\\nOPTIONAL { ?item wdt:P276 ?location_wikidata. }\\n}\\nLIMIT 1000\\nOFFSET 939000\\n\\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:322)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:84)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:123)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'\n",
      "Checkpoint saved at batch 940\n",
      "Fetching data with OFFSET 940000\n",
      "Fetching data with OFFSET 941000\n",
      "Fetching data with OFFSET 942000\n",
      "Fetching data with OFFSET 943000\n",
      "Fetching data with OFFSET 944000\n",
      "Fetching data with OFFSET 945000\n",
      "Fetching data with OFFSET 946000\n",
      "Fetching data with OFFSET 947000\n",
      "Fetching data with OFFSET 948000\n",
      "Fetching data with OFFSET 949000\n",
      "Checkpoint saved at batch 950\n",
      "Fetching data with OFFSET 950000\n",
      "Fetching data with OFFSET 951000\n",
      "Fetching data with OFFSET 952000\n",
      "Fetching data with OFFSET 953000\n",
      "Fetching data with OFFSET 954000\n",
      "Fetching data with OFFSET 955000\n",
      "Fetching data with OFFSET 956000\n",
      "Fetching data with OFFSET 957000\n",
      "Fetching data with OFFSET 958000\n",
      "Fetching data with OFFSET 959000\n",
      "No more data returned.\n",
      "Data retrieval complete. Saved to wikidata_paintings_ids_final.csv\n"
     ]
    }
   ],
   "source": [
    "wikidata_base_query = \"\"\"\n",
    "SELECT ?item ?author_wikidata ?location_wikidata WHERE {{\n",
    "?item wdt:P31 wd:Q3305213.\n",
    "OPTIONAL {{ ?item wdt:P170 ?author_wikidata. }}\n",
    "OPTIONAL {{ ?item wdt:P276 ?location_wikidata. }}\n",
    "}}\n",
    "LIMIT {limit}\n",
    "OFFSET {offset}\n",
    "\"\"\"\n",
    "\n",
    "# Set batch parameters\n",
    "limit = 1000  # Number of records to fetch per batch\n",
    "checkpoint_interval = 10  # Save a checkpoint every 10 batches\n",
    "max_retries = 5  # Maximum number of retries for failed requests\n",
    "\n",
    "# Check if a checkpoint exists to resume from\n",
    "# Create checkpoints folder if it does not exist\n",
    "if not os.path.exists('data/checkpoints'):\n",
    "    os.makedirs('data/checkpoints')\n",
    "    \n",
    "if os.path.exists('data/checkpoints/paintings_ids_checkpoint.csv') and os.path.exists('data/checkpoints/offset_paintings_ids_checkpoint.txt'):\n",
    "    all_data = pd.read_csv('data/checkpoints/paintings_ids_checkpoint.csv')\n",
    "    with open('data/checkpoints/offset_paintings_ids_checkpoint.txt', 'r') as f:\n",
    "        offset = int(f.read())\n",
    "    batch_number = offset // limit\n",
    "    print(f\"Resuming from offset {offset}\")\n",
    "else:\n",
    "    all_data = pd.DataFrame()\n",
    "    offset = 0\n",
    "    batch_number = 0\n",
    "\n",
    "# Loop to fetch data in batches\n",
    "\n",
    "while True:\n",
    "    query = wikidata_base_query.format(limit=limit, offset=offset)\n",
    "    print(f\"Fetching data with OFFSET {offset}\")\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            results = run_sparql_query(query)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}. Retrying ({retries+1}/{max_retries})...\")\n",
    "            retries += 1\n",
    "            time.sleep(5)\n",
    "    else:\n",
    "        print(\"Max retries exceeded. Exiting.\")\n",
    "        break\n",
    "\n",
    "    # Check if the results object is empty or None\n",
    "    if not results or 'results' not in results or 'bindings' not in results['results'] or not results['results']['bindings']:\n",
    "        print(\"No more data returned.\")\n",
    "        break\n",
    "    \n",
    "    # Process the results\n",
    "    bindings = results['results']['bindings']\n",
    "    if not bindings:\n",
    "        print(\"No more data returned.\")\n",
    "        break\n",
    "\n",
    "    # Convert the bindings to a DataFrame\n",
    "    data = []\n",
    "    for b in bindings:\n",
    "        item = b['item']['value']\n",
    "        author_wikidata = b['author_wikidata']['value'] if 'author_wikidata' in b else None\n",
    "        location_wikidata = b['location_wikidata']['value'] if 'location_wikidata' in b else None\n",
    "        data.append({\n",
    "            'item': item,\n",
    "            'author_wikidata': author_wikidata,\n",
    "            'location_wikidata': location_wikidata\n",
    "        })\n",
    "    df = pd.DataFrame(data)\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "    \n",
    "    # Save a checkpoint at specified intervals\n",
    "    batch_number += 1\n",
    "    if batch_number % checkpoint_interval == 0:\n",
    "        all_data.to_csv('data/checkpoints/paintings_ids_checkpoint.csv', index=False)\n",
    "        with open('data/checkpoints/offset_paintings_ids_checkpoint.txt', 'w') as f:\n",
    "            f.write(str(offset + limit))\n",
    "        print(f\"Checkpoint saved at batch {batch_number}\")\n",
    "\n",
    "    # Update the offset for the next batch\n",
    "    offset += limit\n",
    "    time.sleep(1)  # Be polite and avoid overloading the server\n",
    "\n",
    "# Save the final data to a CSV file\n",
    "unique_paintings = all_data.drop_duplicates(subset='item', keep='first')\n",
    "unique_paintings.to_csv('data/wikidata_paintings_ids_final_2.csv', index=False)\n",
    "print(\"Data retrieval complete. Saved to wikidata_paintings_ids_final.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
