{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input data\n",
    "df = pd.read_csv('data/paintings_with_filenames.csv') \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_relevant_sections(text):\n",
    "   \n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    # Define regular expression patterns to match each section\n",
    "    intro_pattern = r'^(.*?)(?=\\n==)'\n",
    "    description_pattern = r'== Description ==\\n(.*?)(?=\\n==|\\Z)'\n",
    "    interpretation_pattern = r'== Interpretations ==\\n(.*?)(?=\\n==|\\Z)'\n",
    "\n",
    "    # Search for each section\n",
    "    intro = re.search(intro_pattern, text, re.DOTALL)\n",
    "    description = re.search(description_pattern, text, re.DOTALL)\n",
    "    interpretation = re.search(interpretation_pattern, text, re.DOTALL)\n",
    "\n",
    "    # Extract the sections, if found\n",
    "    result = \"\"\n",
    "    if intro:\n",
    "        result += intro.group(1).strip() + \"\\n\\n\"\n",
    "    if description:\n",
    "        result += \"== Description ==\\n\" + description.group(1).strip() + \"\\n\\n\"\n",
    "    if interpretation:\n",
    "        result += \"== Subject ==\\n\" + interpretation.group(1).strip()\n",
    "\n",
    "    return result.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['wiki_description'] = df['article_text'].apply(extract_relevant_sections)\n",
    "\n",
    "df['full_description'] = df['title'] + ' ' + df['depicts'] + ' ' + df['wga_description'] + ' ' + df['wiki_description']\n",
    "\n",
    "# Filter out NaN values from 'full_description'\n",
    "df = df.dropna(subset=['full_description'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "df = df[df['full_description'].str.contains('supper', case=False, na=False)]\n",
    "df = df.head(128)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check if MPS is available and set the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Define NER pipeline with batch processing\n",
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if device.type == \"mps\" else -1  # 0 for GPU/MPS, -1 for CPU\n",
    ")\n",
    "\n",
    "# Sample dataframe with descriptions\n",
    "df = pd.DataFrame({\n",
    "    'full_description': [\n",
    "        \"There are herring busses in front of the Rotterdam Gate.\",\n",
    "        \"People are eating fruit.\",\n",
    "        \"The painting shows a cityscape with a harbor.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Define set of food entities for faster lookup\n",
    "food_entities = {'food','wine', 'beverage', 'meat', 'fruit', 'vegetable', 'bread', \n",
    "                'dairy', 'dessert', 'seafood', 'eggs', 'fish'}\n",
    "\n",
    "# Function to check for food entities in a list of NER results\n",
    "def mentions_food_batch(results_batch):\n",
    "    mentions = []\n",
    "    for results in results_batch:\n",
    "        found = any(entity['word'].lower() in food_entities for entity in results)\n",
    "        mentions.append(found)\n",
    "    return mentions\n",
    "\n",
    "# Process descriptions in batches\n",
    "batch_size = 16 \n",
    "descriptions = df['full_description'].tolist()\n",
    "mentions_food = []\n",
    "\n",
    "num_batches = (len(descriptions) + batch_size - 1) // batch_size\n",
    "\n",
    "for i in tqdm(range(0, len(descriptions), batch_size), total=num_batches, desc=\"Processing Batches\", unit=\"batch\", ncols=80, leave=True):\n",
    "    batch_texts = descriptions[i:i + batch_size]\n",
    "    results_batch = ner_pipeline(batch_texts)\n",
    "    mentions_food.extend(mentions_food_batch(results_batch))\n",
    "\n",
    "# Assign the results to the dataframe\n",
    "df['mentions_food'] = mentions_food\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/mentions_food.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[df['mentions_food'] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Device Configuration: Use MPS if available, else CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device\")\n",
    "\n",
    "# 2. Load the Model and Tokenizer\n",
    "model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "# 3. Define the NER Pipeline with Batch Processing\n",
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if device.type == \"mps\" else -1  # 0 for MPS, -1 for CPU\n",
    ")\n",
    "\n",
    "# 4. Sample DataFrame with Descriptions\n",
    "df_test = pd.DataFrame({\n",
    "    'description': [\n",
    "        \"There are herring busses in front of the Rotterdam Gate.\",\n",
    "        \"The painting shows a cityscape with a harbor.\",\n",
    "        \"She enjoys a glass of wine with her dinner.\",\n",
    "        \"Fresh vegetables are essential for a healthy diet.\",\n",
    "        \"The conference was attended by experts in marine biology.\",\n",
    "        \"They served delicious seafood at the restaurant.\",\n",
    "        \"He bought eggs and bread from the store.\",\n",
    "        \"A variety of fruits are available at the market.\",\n",
    "        \"The dairy products were of high quality.\",\n",
    "        \"She prepared a vegetable salad for lunch.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# 5. Get and Print Entity Labels from the Model\n",
    "labels = model.config.id2label\n",
    "print(\"\\nEntity labels in the model:\")\n",
    "for id, label in labels.items():\n",
    "    print(f\"{id}: {label}\")\n",
    "\n",
    "# 6. Define Entity Labels for Food\n",
    "food_entity_labels = {'FOOD'}  # Adjust based on model's entity_group labels\n",
    "\n",
    "# 7. Function to Check for Food Entities in a Batch\n",
    "def mentions_food_batch(results_batch):\n",
    "    mentions = []\n",
    "    for results in results_batch:\n",
    "        found = any(entity['entity_group'] in food_entity_labels for entity in results)\n",
    "        mentions.append(found)\n",
    "    return mentions\n",
    "\n",
    "# 8. Function to Print NER Results for Each Description\n",
    "def print_ner_results(descriptions, results_batch, start_index):\n",
    "    for idx, (description, entities) in enumerate(zip(descriptions, results_batch)):\n",
    "        absolute_idx = start_index + idx\n",
    "        print(f\"\\nDescription [{absolute_idx}]: {description}\")\n",
    "        if entities:\n",
    "            print(\"NER Entities:\")\n",
    "            for entity in entities:\n",
    "                print(f\"  - {entity['word']} ({entity['entity_group']}) [Score: {entity['score']:.3f}]\")\n",
    "        else:\n",
    "            print(\"NER Entities: None\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "# 9. Process Descriptions in Batches with Progress Tracking and NER Results Printing\n",
    "batch_size = 4  # Adjust based on memory constraints and readability\n",
    "descriptions = df_test['description'].tolist()\n",
    "mentions_food = []\n",
    "\n",
    "# Calculate the number of batches\n",
    "num_batches = (len(descriptions) + batch_size - 1) // batch_size\n",
    "\n",
    "# Flag to control verbosity (set to True to print all results)\n",
    "verbose = True\n",
    "\n",
    "# Use tqdm to display a progress bar\n",
    "for batch_num, i in enumerate(tqdm(range(0, len(descriptions), batch_size), total=num_batches, desc=\"Processing Batches\")):\n",
    "    batch_texts = descriptions[i:i + batch_size]\n",
    "    results_batch = ner_pipeline(batch_texts)\n",
    "    \n",
    "    # Append the mention_food results\n",
    "    mentions_food.extend(mentions_food_batch(results_batch))\n",
    "    \n",
    "    # Print NER results for the current batch\n",
    "    if verbose:\n",
    "        print_ner_results(batch_texts, results_batch, i)\n",
    "\n",
    "# 10. Assign the Results to the DataFrame\n",
    "df_test['mentions_food'] = mentions_food\n",
    "\n",
    "# 11. Display the Final DataFrame\n",
    "print(\"\\nFinal Results:\")\n",
    "print(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
