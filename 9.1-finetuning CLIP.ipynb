{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/paintings_with_food_nlp.csv')\n",
    "df['has_food'] = df.iloc[:, 2:].sum(axis=1) > 0\n",
    "df = df[['item', 'image_path', 'has_food']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming your dataframe is called df\n",
    "print(\"Total samples:\", len(df))\n",
    "print(\"With food:\", sum(df['has_food']))\n",
    "print(\"Without food:\", sum(~df['has_food']))\n",
    "print(\"Ratio food/no-food:\", sum(df['has_food'])/len(df))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_input(image_path, has_food, processor):\n",
    "    \"\"\"Process a single image and create corresponding text\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    text = 'a painting containing food' if has_food else 'a painting not containing food'\n",
    "    \n",
    "    # Process image and text using CLIP processor\n",
    "    inputs = processor(\n",
    "        images=image,\n",
    "        text=[text],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        max_length=77,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    # Add label\n",
    "    inputs['labels'] = torch.tensor([float(has_food)])\n",
    "    return inputs\n",
    "\n",
    "def create_batch(samples):\n",
    "    \"\"\"Collate function to create batches\"\"\"\n",
    "    batch = {\n",
    "        'pixel_values': torch.stack([x['pixel_values'][0] for x in samples]),\n",
    "        'input_ids': torch.stack([x['input_ids'][0] for x in samples]),\n",
    "        'attention_mask': torch.stack([x['attention_mask'][0] for x in samples]),\n",
    "        'labels': torch.stack([x['labels'] for x in samples])\n",
    "    }\n",
    "    return batch\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            pixel_values=batch['pixel_values']\n",
    "        )\n",
    "        \n",
    "        # Get image and text features\n",
    "        image_features = outputs.image_embeds\n",
    "        text_features = outputs.text_embeds\n",
    "        \n",
    "        # Compute similarity scores\n",
    "        similarity = torch.sum(image_features * text_features, dim=-1)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.binary_cross_entropy_with_logits(similarity, batch['labels'])\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, eval_loader, device):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_loader, desc=\"Evaluating\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                pixel_values=batch['pixel_values']\n",
    "            )\n",
    "            \n",
    "            image_features = outputs.image_embeds\n",
    "            text_features = outputs.text_embeds\n",
    "            similarity = torch.sum(image_features * text_features, dim=-1)\n",
    "            \n",
    "            loss = F.binary_cross_entropy_with_logits(similarity, batch['labels'])\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predictions.extend(torch.sigmoid(similarity).cpu().numpy())\n",
    "            true_labels.extend(batch['labels'].cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions) > 0.5\n",
    "    accuracy = (predictions == np.array(true_labels)).mean()\n",
    "    \n",
    "    return total_loss / len(eval_loader), accuracy\n",
    "\n",
    "def train_model(df, num_epochs=3, batch_size=16, learning_rate=5e-5):\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    # Set device\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model and processor\n",
    "    model_name = \"openai/clip-vit-base-patch32\"\n",
    "    processor = CLIPProcessor.from_pretrained(model_name)\n",
    "    model = CLIPModel.from_pretrained(model_name)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Split data\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Process datasets\n",
    "    train_samples = [\n",
    "        prepare_input(row['image_path'], row['has_food'], processor)\n",
    "        for _, row in tqdm(train_df.iterrows(), desc=\"Processing train data\")\n",
    "    ]\n",
    "    \n",
    "    val_samples = [\n",
    "        prepare_input(row['image_path'], row['has_food'], processor)\n",
    "        for _, row in tqdm(val_df.iterrows(), desc=\"Processing val data\")\n",
    "    ]\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_samples,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=create_batch\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_samples,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=create_batch\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_loss, accuracy = evaluate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), 'best_food_detector.pth')\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "def predict(image_path, model, processor, device):\n",
    "    \"\"\"Make prediction for a single image\"\"\"\n",
    "    inputs = prepare_input(image_path, False, processor)  # label doesn't matter here\n",
    "    \n",
    "    # Move to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            pixel_values=inputs['pixel_values']\n",
    "        )\n",
    "        \n",
    "        image_features = outputs.image_embeds\n",
    "        text_features = outputs.text_embeds\n",
    "        similarity = torch.sum(image_features * text_features, dim=-1)\n",
    "        \n",
    "    probability = torch.sigmoid(similarity).cpu().numpy()[0]\n",
    "    return probability > 0.5, probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_balanced_data(df, balance_strategy='undersample'):\n",
    "    \"\"\"\n",
    "    Balance the dataset using different strategies\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'has_food' column\n",
    "    - balance_strategy: 'undersample', 'oversample', or 'weighted'\n",
    "    \n",
    "    Returns:\n",
    "    - Balanced DataFrame or (DataFrame, sample_weights)\n",
    "    \"\"\"\n",
    "    food_samples = df[df['has_food']]\n",
    "    no_food_samples = df[~df['has_food']]\n",
    "    \n",
    "    print(f\"Original distribution:\")\n",
    "    print(f\"Food samples: {len(food_samples)}\")\n",
    "    print(f\"No food samples: {len(no_food_samples)}\")\n",
    "    \n",
    "    if balance_strategy == 'undersample':\n",
    "        # Undersample majority class\n",
    "        no_food_balanced = resample(\n",
    "            no_food_samples,\n",
    "            replace=False,\n",
    "            n_samples=len(food_samples),\n",
    "            random_state=42\n",
    "        )\n",
    "        balanced_df = pd.concat([food_samples, no_food_balanced])\n",
    "        print(f\"\\nAfter undersampling:\")\n",
    "        print(f\"Total samples: {len(balanced_df)}\")\n",
    "        return balanced_df\n",
    "        \n",
    "    elif balance_strategy == 'oversample':\n",
    "        # Oversample minority class\n",
    "        food_balanced = resample(\n",
    "            food_samples,\n",
    "            replace=True,\n",
    "            n_samples=len(no_food_samples),\n",
    "            random_state=42\n",
    "        )\n",
    "        balanced_df = pd.concat([food_balanced, no_food_samples])\n",
    "        print(f\"\\nAfter oversampling:\")\n",
    "        print(f\"Total samples: {len(balanced_df)}\")\n",
    "        return balanced_df\n",
    "        \n",
    "    elif balance_strategy == 'weighted':\n",
    "        # Calculate class weights\n",
    "        total_samples = len(df)\n",
    "        weight_for_0 = (1 / len(no_food_samples)) * (total_samples / 2)\n",
    "        weight_for_1 = (1 / len(food_samples)) * (total_samples / 2)\n",
    "        \n",
    "        sample_weights = np.where(df['has_food'], weight_for_1, weight_for_0)\n",
    "        print(\"\\nUsing weighted sampling\")\n",
    "        print(f\"Weight for no food: {weight_for_0:.3f}\")\n",
    "        print(f\"Weight for food: {weight_for_1:.3f}\")\n",
    "        return df, sample_weights\n",
    "\n",
    "def modify_train_function_for_weights(train_model_fn):\n",
    "    \"\"\"\n",
    "    Modify the training function to use sample weights\n",
    "    \"\"\"\n",
    "    def weighted_loss(predictions, targets, weights):\n",
    "        return F.binary_cross_entropy_with_logits(\n",
    "            predictions, \n",
    "            targets,\n",
    "            weight=weights,\n",
    "            reduction='mean'\n",
    "        )\n",
    "    \n",
    "    # Modify the training loop to include weights\n",
    "    def train_epoch_weighted(model, train_loader, optimizer, device):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                pixel_values=batch['pixel_values']\n",
    "            )\n",
    "            \n",
    "            image_features = outputs.image_embeds\n",
    "            text_features = outputs.text_embeds\n",
    "            similarity = torch.sum(image_features * text_features, dim=-1)\n",
    "            \n",
    "            loss = weighted_loss(\n",
    "                similarity, \n",
    "                batch['labels'],\n",
    "                batch['weights'].to(device)\n",
    "            )\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        return total_loss / len(train_loader)\n",
    "    \n",
    "    return train_epoch_weighted\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    \n",
    "    # Choose one of these approaches:\n",
    "    \n",
    "    # 1. Undersampling approach\n",
    "    balanced_df = prepare_balanced_data(df, 'undersample')\n",
    "    \"\"\"  # 2. Oversampling approach\n",
    "    balanced_df = prepare_balanced_data(df, 'oversample')\n",
    "    model, processor = train_model(balanced_df)\n",
    "    \n",
    "    # 3. Weighted approach\n",
    "    df, sample_weights = prepare_balanced_data(df, 'weighted')\n",
    "    # You'll need to modify the train_model function to use weights \"\"\"\n",
    "    \n",
    " # Train model\n",
    "    model, processor = train_model(df)\n",
    "    \n",
    "    # Example prediction\n",
    "    image_path = \"test_image.jpg\"\n",
    "    has_food, confidence = predict(image_path, model, processor, \n",
    "                                 torch.device('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "    print(f\"Contains food: {has_food} (confidence: {confidence:.2f})\")\n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Choose one of these approaches:\n",
    "\n",
    "# 1. Undersampling approach\n",
    "balanced_df = prepare_balanced_data(df, 'undersample')\n",
    "\n",
    "\"\"\"  # 2. Oversampling approach\n",
    "balanced_df = prepare_balanced_data(df, 'oversample')\n",
    "model, processor = train_model(balanced_df)\n",
    "\n",
    "# 3. Weighted approach\n",
    "df, sample_weights = prepare_balanced_data(df, 'weighted')\n",
    "# You'll need to modify the train_model function to use weights \"\"\"\n",
    "\n",
    "# Train model\n",
    "model, processor = train_model(df)\n",
    "\n",
    "# Example prediction\n",
    "image_path = \"test_image.jpg\"\n",
    "\n",
    "has_food, confidence = predict(image_path, model, processor, torch.device('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "\n",
    "print(f\"Contains food: {has_food} (confidence: {confidence:.2f})\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
